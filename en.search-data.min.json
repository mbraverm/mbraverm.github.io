[{"id":0,"href":"/posts/","title":"News","parent":"Mark Braverman","content":""},{"id":1,"href":"/about/","title":"About","parent":"Mark Braverman","content":""},{"id":2,"href":"/about/brief-bio/","title":"Brief Bio","parent":"About","content":"I received my BA in mathematics and computer science in 2001 from the Technion.\nI received my PhD in 2008 from the Department of Computer Science at the University of Toronto under the supervision of Stephen Cook. My thesis was on the computability and complexity of Julia sets, a topic on which I worked with Michael Yampolsky.\nBetween 2008 and 2010 I spent two years as a postdoctoral researcher at the Microsoft Research New England lab, then run by Jennifer Chayes.\nIn 2010-11 I was an assistant professor jointly appointed at the Departments of Mathematics and Computer Science at the University of Toronto.\nI have been a professor of computer science at Princeton University since 2015. I joined Princeton in 2011 as an assistant professor.\nWith my students and postdocs I work on theoretical computer science, and its connections to other disciplines, especially in information theory, mathematical analysis, and economics. You can find my publications here. My research is supported by a number of awards, including a 2013 Packard Fellowship and a 2019 NSF Waterman award.\n"},{"id":3,"href":"/team/members/","title":"Members","parent":"Group","content":"Current Group Members Graduate students:  Antonio Molina Lovett  Postdocs:  Mahsa Derakhshan Vijay Bhattiprolu John Peebles Or Zamir  Alumni: With first place of employment/study:\nGraduate students  Sumegha Garg PhD in Computer Science, Princeton, 2020; Rabin Postdoctoral Fellow at Harvard. Young Kun Ko PhD in Computer Science, Princeton, 2018; Assistant Professor / Faculty Fellow at NYU. Jieming Mao PhD in Computer Science, Princeton, 2018; Google Research New York. Jonathan Schneider, PhD in Computer Science, Princeton, 2018; Google Research New York. Ankit Garg, PhD in Computer Science, Princeton, 2016; Microsoft Research New England. Omri Weinstein, PhD in Computer Science, Princeton, 2015; NYU postdoc supported by the Simons Society of Fellows. Anastasios Zouzias, PhD in Computer Science, Toronto, 2013; IBM Research, Zurich. Wei Xi Fan, MSc in Mathematics, Toronto, 2011; Google Canada. Rinoc Johnson, MSc in Mathematics, Toronto, 2011; MapleSoft.  Postdocs I supervised or worked with closely  Sahil Singla, 2018-2021, Princeton; Faculty at GA Tech. Shay Moran, 2017-2020, IAS, Princeton, and Google; Faculty at the Technion, Israel. Dor Mintzer, 2018-2020, IAS; Faculty at MIT. Sepehr Assadi, 2018-2019, Princeton; Faculty at Rutgers University. Gil Cohen, 2016-18, Princeton; Faculty at Tel-Aviv University, Israel. Ran Gelles, 2014-16, Princeton; Faculty at Bar-Ilan University, Israel. Matt Weinberg, 2014-16, Princeton; Faculty at Princeton University. Rotem Oshman, 2013-14, Princeton; Faculty at Tel-Aviv University, Israel. Klim Efremenko, 2012-13, IAS; Postdoc at the University of Chicago. Ankur Moitra, 2011-13, IAS; Faculty at MIT. Jing Chen, 2012-13, IAS; Faculty in Stony Brook University. Eden Chlamtac, 2010, Toronto; Faculty in Ben Gurion University, Be\u0026rsquo;er Sheva, Israel. Per Austrin, 2010-11, Toronto; Faculty in KTH, Stockholm, Sweden. Cristobal Rojas, 2010-11, Toronto; Faculty in Universidad Andres Bello, Santiago, Chile.  Undergraduate students See this list of past advised projects.\n"},{"id":4,"href":"/about/affiliations/","title":"Affiliations and service","parent":"About","content":" Princeton Computer Science Theory Group PACM (Program in Applied and Computational Mathematics) Simons Institute for the Theory of Computing Scientific Advisory Board Foundations of Computational Mathematics Board of Directors  "},{"id":5,"href":"/research/dynamics-and-computation/","title":"Dynamics and computation","parent":"Research","content":"A dynamical system is a stateful system (often with a continuous state space) evolving over time. Thus, dynamical systems can be (and are being) used to capture the behavior of both natural and articifical systems over time. The state space of dynamical systems is typically continuous, which means that one has to look at continuous models of computation. Here is a short 2013 Communications of the ACM article I wrote explaining computation over the reals. There is also an older 2006 article with Stephen Cook in the Notices of the AMS.\nThere are at least two natural connections between dynamics and computation. In one direction, the question \u0026ldquo;which properties of which dynamical systems can be computed and how efficiently?\u0026quot; is foundational to mapping the limits of applied mathematics. In the opposite direction, \u0026ldquo;how powerful a computation can a given dynamical system simulate robustly?\u0026quot; touches upon the Church-Turing thesis and questions of hypercomputation.\n Which properties of dynamical systems can be computed? The case of Julia sets Dynamical systems as computational devices and the Space-Bounded Church-Turing Thesis  Which properties of dynamical systems can be computed? The case of Julia sets Julia sets are some of the most visualized objects in Mathematics. They arise in the study of complex dynamics (that is, the state space if the set $\\mathbb{C}$ of complex numbers, visualized on the plane), along with the Mandelbrot set. From the scientific perspective, the family of Julia sets and the complex dynamics that gives rise to them, are sufficiently rich to exhibit phenomena one sees in the \u0026ldquo;wild\u0026rdquo;. At the same time, after 100+ years of deep study, we know a lot about them, making them good \u0026ldquo;lab models\u0026rdquo; for more general dynamical systems. Computer programs had been written to visualize Julia sets (by amateur programmers and professional mathematicians alike). Thus questions about computational properties of Julia sets are natural to consider, and may shed light on the broader set of phenomena we should expect in \u0026ldquo;computablility of dynamical systems\u0026rdquo;.\nConsider the quadratic function $f_c:\\mathbb{C}\\rightarrow \\mathbb{C}$ given by $f_c(z):=z^2+c$. For any initial point $z_0$, the mapping $f_c$ induces a (discrete-time) trajectory of the evolution of $z$ under $f_c$: $z_1=f_c(z_0)=z_0^2+c$, $z_2=f_c(z_1)=(z_0^2+c)^2+c$, and more generally $z_{t+1}=f_c(z_t)$.\nThis evolution, viewed as a dynamical system, raises quesitons of the form \u0026ldquo;what will happen to the trajectory eventually?\u0026quot; and \u0026ldquo;what can be said about the set of trajectories as a whole?\u0026quot;.\nIf $|z_0|$ is sufficiently large, e.g. $|z_0|\u0026gt;|c|+1$, then we will have $|z_1|\u0026gt;|z_0|$, and the trajectory will rapidly escape to $\\infty$. On the other hand, if $z_0$ is a root of the polynomial $z^2+c=z$, then it will be a fixed point of the dynamical system, and its trajectory will not escape to $\\infty$. The filled Julia set in this case is the set of initial conditions for which the dynamics does not escape to $\\infty$: $$ K_c:=\\lbrace z_0: z_t\\nrightarrow\\infty\\rbrace. $$ The Julia set is the boundary of $K_c$: $J_c:=\\partial K_c$. It is the set of points around which the long-term behavior is unstable: if $z\\in J_c$, then any neighborhood of $z$ contains both points whose trajectories escape to $\\infty$ and those whose trajectories stay bounded.\nAs it turns out, there exist non-computable quadratic Julia sets:\nTheorem [BY'06]: There exists a parameter $c$ such that no Turing Machine with access to parameter $c$ can compute arbitrarily precise picture of $J_c$.\nMoreover, it turns out that such a $c$ can be computed explicitly [BR07].\nWhen a non-computability result is present, one might expect non-computability to be the rule, and computational tractability to be a lucky exception. Quadratic Julia sets are an interesting case-study, since they are rich enough to support many dynamically interesting behaviors, but are sufficiently well-understood to allow us to answer most questions about their computational properties. Surprisingly, non-computability sometimes occurs, but it is the exception.\nIn fact, by several measures, we either know that \u0026ldquo;most\u0026rdquo; quadratic Julia sets are computable, or strongly suspect that they are. Intuitively, the non-computable examples are constructed by carefully encoding a computationally difficult function into the parameter $c$ at infinitely many scales (more precisely, the encoding uses a continued fraction expansion). Perturbing $c$ by even a tiny amount will destroy most of this encoding.\nDynamical systems as computational devices and the Space-Bounded Church-Turing Thesis Returning to the broader question of \u0026ldquo;which properties of dynamical systems can be computed?\u0026rdquo;, one can loosely calssify computational hardness results into two categories: \u0026ldquo;systems that can simulate generic computation\u0026rdquo; and \u0026ldquo;problems into which hard-to-compute functions can be carefully woven\u0026rdquo;.\nIf a dynamical system is rich enough to simulate a Turing Machine (and thus generic computation), then diagonalization results starting with the intractability of the Halting Problem and the time hierarchy theorems imply that the only way to answer questions about their long-term behavior is through simulation. Cellular automata generally belong to this category.\nEven if a dynamical system is not rich enough to simulate generic computation, one can still carefully reduce some non-computable function to some long-term property of the dynamical system. It is very unlikely that all computation can be encoded into iterations of a fixed quadratic polynomial over $\\mathbb{C}$), but we can carefully construct a $c$ such that computing arbitrarily high precision images of $J_c$ is as hard as solving the Halting Problem.\nA closely related question is that of robustness. If we perturb the dynamical system a little bit, will the non-computability phenomenon disappear? One would expect the answer to be \u0026lsquo;yes\u0026rsquo; in the second case, and \u0026lsquo;depends\u0026rsquo; in the first case. If the non-computable example had to be carefully constructed, then noise is likely to destroy it (as it does in the case of quadratic Julia sets). More generally, what can be said about the computational complexity of noisy dynamical systems?\nIn full generality, this question is too philosophical to be precisely formulated as a purely mathematical conjecture. It is similar in flavor to the Church-Turing Thesis that asserts that all physically relevant dynamical systems are at most as powerful as a Turing Machine (or any other general-purpose computing device) for the purposes of computability. The best-known quantitative refinement of the CT Thesis, sometimes called the Extended Church-Turing Thesis (probably falsly \u0026ndash; see quantum computing) extends the connection to time complexity: any computation by a dynamical system can be efficiently simulated in time polynomial in the size of the system and its original runtime. Relatively little attention has been given to space (that is memory) complexity in this context, even though memory complexity is a more robust notion, and is easier to interpret than time in the context of dynamical systems.\nThe reason that properties of dynamical systems under noise become computationally tractable is that in the presense of noise these systems are only able to maintain a limited amount of memory over time. A system capable of robustly representing only $2^M$ distinct states (corresponding to $M$ bits of memory) can be analyzed by a Turing Machine using only $poly(M)$ memory (though potentially in time exponential in $M$). How one might define the amount of \u0026ldquo;memory\u0026rdquo; a system has? Information theory comes in handy here.\nSuppose the evolution of the system is given by the sequence $X_1,X_2,\\ldots$, where $X_{t+1}$ is obtained from $X_t$ as $$X_{t+1}=N_\\varepsilon(\\Phi(X_t)),$$ where $\\Phi(X_t)$ is the (noiseless) evolution rule, and $N_\\varepsilon$ is a noise operator. We can define the memory of the system as: $$ M:= I(X_{t+1};X_t), $$ the amount of information the next step retains about the previous one.\nThe system\u0026rsquo;s dimension plays a critical role in the amount of memory it retains. If the state space of $X_t$ is bounded and has $d$ dimensions, then under random noise of magnitude $\\varepsilon$ we should expect the memory to be $M\\sim d\\cdot \\log (1/\\varepsilon)$: memory scales liniarly in dimension but only logarithmically in the noise.\nWith a \u0026ldquo;definition\u0026rdquo; of memory at hand, we can postulated a space complexity version of the Church-Turing thesis. We call it the Space-Bounded Church-Turing thesis (SBCT):\nSpace-Bounded Church-Turing thesis [BRS'15]: A dynamical system with memory capacity $M$ is at most as powerful as a Turing Machine with $poly(M)$ bits of memory.\nUnlike the extended-CT (which talks about time complexity), SBCT does not appear to contradict our current understanding of the limits of quantum computing. A stronger (and mathematically more formalizable) assertion is that whenever the noise itself is computationally simple (and thus is not a source of more computational complexity), long-term properties of a system with $M$ bits of memory can be computed by a Turing Machine with $poly(M)$ space. This indeed can be shown in some interesting special cases [BRS'17].\nThe SBCT is consistent with the fact that non-computability in the context of Julia sets is not robust to noise. The state space over which the dynamics defining the Julia sets operates is $\\mathbb{C}$, with error $\\varepsilon$ such a system only has $\\sim\\log (1/\\varepsilon)$ memory. On the other hand, the memory of a cellular automaton (even with noise) scales with the size of its board (each cell can \u0026ldquo;remember\u0026rdquo; $\\sim 1$ bit of information), which is typically infinite. Therefore, their long-term properties are potentially undecidable even in the presense of noise, again, consistently with SBCT.\nFurther reading Surveys on computing over the reals:\n Notices of the AMS, 2006 Communications of the ACM, 2013  On Julia sets:\nBook: Computability of Julia Sets\nMark Braverman, Michael Yampolsky\nSpringer, 2009\n[Amazon] [Springer]\nOn computability in dynamics more generally and the Space-Bounded Church-Turing thesis:\n A 2012 talk I gave at the 2012 Turing Centenary conference in Manchester. A phys.org article about the SBCT.  "},{"id":6,"href":"/research/information-complexity/","title":"Information complexity","parent":"Research","content":"Information theory is a vastly successful theory underpinning much of our communication technology. In many important communication scenarios it allows one to calculate the precise amount of resources needed to perform a cetrain task. For example, the number of bits Alice needs to communicate to send a string $x_1 x_2 \\ldots x_n$ of $n$ random trits (elements from $\\lbrace 1,2,3\\rbrace$) to Bob is given by $(\\log_2 3) \\cdot n \\pm o(n)$. The number of bits Alice needs to communicate to send $n$ random trits to Bob if Bob already knows half of the $x$\u0026rsquo;s (regarless of whether Alice knows which locations are known to Bob) is $\\frac{\\log_2 3}{2}\\cdot n \\pm o(n)$ etc. These quantities can be written as expressions in terms of things like Shannon\u0026rsquo;s entorpy, mutual information, and conditional mutual information.\nNotions of entropy and mutual information allow to precisely (and losslessly!) describe the flow of information in a variety of settings. They also allow to one to write \u0026ldquo;common sense\u0026rdquo; statements about information in precise mathematical terms which can then be manipulated. This turns out to be extremely useful in reasoning about communication. For example entropy $H(M)$ represents the amount of uncertainty in a message $M$. Mutual information $I(M;X)$ represents the amount of information the message $M$ reveals about a piece of data $X$. Conditional mutual information $I(M; X|Y)$ represents the amount of information a message $M$ reveals about $X$ to someone who already knows a piece of data $Y$.\nThe chain rule $$ I(M_1 M_2; X) = I(M_1; X) + I(M_2; X|M_1) $$ is just a precise way to formalize the intuitive fact that what one learned from two messages $M_1 M_2$ about $X$ can be decomposed into what one learned from the first message plus what one learned from the second message when we already knew the first one. The data processing inequality $$ I(X;F(Y)) \\le I(X;Y) $$ formalizes the intuition that a function computed on $Y$ cannot reveal more about $X$ than $Y$ itself.\nThe goal of information complexity is to learn to apply information-theoretic formalism to computational settings. As of now (2021), these tend to work beautifully in models of computation that are simple enough to not support information-theoretically secure computation. Understanding why exactly this happens is an interesting direction for future work. Below we give some examples of results based on information complexity from the 2010-2020 period. In some cases the results are new, while in others they give conceptually simpler proofs or more general statements of existing theorems.\nTwo party communication In the two-party communication complexity setting, two players (Alice and Bob) are given inputs $X$ and $Y$. They are also allowed to use a randomness source $R$. A protocol $\\pi$ is just a formalization of a conversation: each message in $\\pi$ is allowed to depend on the speaker\u0026rsquo;s input, on the conversation so far, and on the public randomness. The communication cost of a protocol is the number of bits communicated during its execution. The communication complexity $CC(T)$ of a task $T$ is the smallest communication cost of a protocol $\\pi$ solving $T$. In the context of communication complexity, $T$ is typically the task of \u0026ldquo;computing a given function $F(X,Y)$ with error probability $\u0026lt;\\varepsilon$\u0026rdquo;.\nAn instructive example is the Equality problem. Alice is given an $n$-bit string $X$, Bob is given an $n$-bit string $Y$, and they would like to determine whether $X=Y$. It can be shown that this can be accomplished with error $\u0026lt;\\varepsilon$ using $k \\sim \\log (1/\\varepsilon)$ bits of communication. Alice will compute a random hash $h(X)$ of lenght $k$ on her input $X$ and send the value to Bob. Bob will compare $h(X)$ to $h(Y)$, and will return \u0026lsquo;equal\u0026rsquo; if they match. There is a $2^{-k}$ probability of hash collision, which means that \u0026lsquo;equal\u0026rsquo; is returned with probability $\\approx 2^{-k}$ even when $X\\neq Y$. Interestingly, a zero-error protocol for equality requires $n+1$ bits of communication.\nAnother function with many applications in lower bounds is Disjointness. Alice and Bob are given subsets $X,Y\\subset \\lbrace 1,\\ldots,n\\rbrace$ (wich can be represented as length-$n$ bit-strings), and need to determine whether they have an element in common. $Disj_n(X,Y)=1$ if the sets are disjoint, and $0$ if they intersect.\nDirect sum and information complexity The direct sum problem (in any model of computation) asks whether it costs $k$ times as much to perform $k$ independent copies of a task $T$ as it costs to perform one copy, or whether one gets a \u0026ldquo;volume discount\u0026rdquo;. When direct sum holds, one gets a powerful lower bounds tool \u0026mdash; a lower bound $L$ on $T$ gets amplified into a lower bound of $k\\cdot L$ on the task $T^k$ of performing $k$ copies of $T$. When direct sum fails, new interesting algorithms follow. A famous example of such a failure is matrix-vector multiplication. A counting argument shows that one needs $\u0026gt;n^2$ operations to mutiply an $n\\times n$ matrix $A$ by a vector $v$. At the same time, multiplying $A$ by $n$ different vectors $v_1,\\ldots,v_n$ is just the problem of multiplying two $n\\times n$ matrices, which can be done faster than $n\\cdot n^2=n^3$ via fast matrix multiplication.\nThe Direct Sum Problem for randomized communication complexity asked whether the direct sum property holds for randomized communication complexity. That is, whether $CC(T^k)\\gtrsim k\\cdot CC(T)$? It turns out that trying to answer this question is closely related to understanding the information complexity of $F$.\nInformation complexity is defined similarly to communication complexity, with information cost replacing communication cost. The (two-party) information cost of a protocol $\\Pi$ on inputs $(X,Y)$ is defined to be the amount of information the participants learn about each other\u0026rsquo;s inputs during the execution of the protocol. Fortunately, the information-theoretic notation makes this quantity easy to formalize: $$ IC(\\Pi):= I(X;\\Pi|Y) + I(Y;\\Pi|X). $$ The first term corresponds to what Bob (who knows $Y$) learns about Alice\u0026rsquo;s input ($X$) from the protocol $\\Pi$. The second term corresponds to what Alice learns. The information complexity of a task $T$ over inputs $(X,Y)$ is defined as the smallest possible information cost of a protocol solving $T$. $$ IC(T):= \\inf_{\\text{$\\Pi$ solves $T$}} IC(\\Pi). $$ The infimum here is necessary, since it is possible that there is a sequence of successful protocols $\\Pi_1,\\Pi_2,\\ldots$ that get ever longer while revealing an ever smaller amount of information (in fact, this happens for the simple task of computing the two-bit AND function).\nIt turns out that the amortized (per-copy) communication complexity of a task $T$ is equal to its information complexity, at least when a vanishing amount of error is allowed. Let $T(X,Y)$ be a task that allows for a small amount of error $\\ve=o(1)$. Let $CC(T^k)$ be the communication complexity of $k$ copies of $T$, and let $IC(T)$ be its information complexity. Then information is equal to amortized communication:\nTheorem [BR'11]: $\\displaystyle{\\lim_{k\\rightarrow\\infty} \\frac{CC(T^k)}{k} = IC(T)}$.\nInteractive compression This theorem gives an immediate blueprint for proving direct sum theorems for (randomized) communication complexity. To show (for example) that $CC(T^k) \\gtrsim k\\cdot CC(T)$, one can show that $IC(T)\\gtrsim CC(T)$. This inequality, more commonly written as $CC(T)\\lesssim IC(T)$ is known as the interactive compression question. It asks whether a protocol $\\pi$ that solves $T$ while revealing little information can be \u0026ldquo;compressed\u0026rdquo; into a protocol $\\pi'$ that uses little communication.\nIn the context of one-way communication near-perfect compression is generally possibly. For example Huffman coding allows one to encode a message with entropy $H(M)$ using at most $H(M)+1$ bits in expectation. It is generally the case that a protocol with $r$ rounds of communication can be compressed into $O(IC(\\Pi)+r)$ bits of communication. Unfortunately, the protocol achieving $IC(T)$ may have an unbounded number of rounds, making such a compression useless in the general interactive setting.\nIt turns out that it is possible to compress a general protocol $\\pi$ whose information cost is $I$ and whose communication cost is $C$ into a protocol $\\pi'$ whose communication cost is $\\tilde{O}(\\sqrt{I\\cdot C})$. This leads to a partial direct sum theorem for randomized communication:\nTheorem [BBCR'10]: $\\displaystyle{CC(T^k)}=\\tilde{\\Omega}(\\sqrt{k}\\cdot CC(T))$.\nAt the same time, Ganor, Kol, and Raz showed a separation between information and communication complexity:\nTheorem [GKR'15]: There is a family of functions whose information complexity is $n$ and whose communication complexity is $2^{\\Omega(n)}$.\nMoreover, it can be shown that this separation is tight - communication complexity is always at most exponential in information complexity. The GKR'15 theorem rules out a tight direct sum theorem for communication complexity. It still remains open whether the $\\sqrt{k}$ in BBCR'10 can be improved, e.g. to $k^{1-\\varepsilon}$.\nDirect product and parallel repetition: using information formalism In light of the BR'11 and GKR'15 results, information complexity becomes the \u0026ldquo;correct\u0026rdquo; measure for studying amortized cost of two-player randomized communication complexity. The connection from BR'11 between information and amortized communication can be further deepened by a direct product theorem. A direct sum theorem gives a lower bound on the amount of resources required to accomplish $k$ copies of a task. A direct product theorem further says that trying to solve $k$ copies of the task with fewere resources will fail except with an exponentially small probability.\nTheorem [BRWY'13,BW'14]: If $I$ bits of information are required to compute a single copy of a function $f(x,y)$ under an input distribution $\\mu$, then any communication protocol that attempts to solve $k$ copies of $f$ with input distributed according to $\\mu^k$ using $o(k\\cdot I)$ bits of communication will fail except with an exponentially small probabiliy $2^{-\\Omega(k)}$.\nAt the heart of the proof of the direct product theorem is applying information-theoretic formalism which treats the \u0026ldquo;success event\u0026rdquo; as just another piece of information. Formalism such as the chain rule allows to make statements of the form \u0026ldquo;succeeding on the first copy does not reveal too much about inputs to the second copy\u0026rdquo; formal.\nPreviously, such reasoning has been used successfully to prove the parallel repetition theorem for two-prover games. Two-prover games warrant a separate discussion, but it should be mentioned that formalism from the direct product theorem from communication complexity can be lifted to re-prove the parallel repetition theorem, and give the only known proof of the parallel repetition theorem in the low-success-probability regime [BG'15].\nThe two-bit AND function and Disjointness Turning from abstract complexity-theoretic results to concrete ones, let us consider the information complexity of specific functions. The simplest functions are ones are of the form $f:\\lbrace 0,1\\rbrace\\times\\lbrace 0,1\\rbrace \\rightarrow \\lbrace 0,1\\rbrace$, where Alice and Bob are each given a single bit of input. Of those, only the AND function (and equivalent transformations) is interesting from the information complexity perspective. Other functions are either constant, amount to one-way data transmission (projection functions), or to a two-way data-exchange (the XOR function).\nGenerally speaking, we do not know an efficient procedure for computing the information complexity of a function from its truth table. In fact, even proving that information complexity is computable appears to be non-trivial [BS'16]. Fortunately, in the case of the two-bit AND, it is possible to describe the information-theoretically optimal protocol.\nGenerally speaking, the optimal protocol depends not only on the function $f$ being computed but also on the prior distribution $\\mu$ of inputs - this is because the amount of information revealed by a protocol $\\pi$ depends on the prior distribution $\\mu$.\nLet $f(x,y)=x\\wedge y$ be the two-bit AND function, and assume, for simplicity, that the prior distribution $\\mu$ is symmetric: $\\mu(0,1)=\\mu(1,0)$.\nThe ascending clock protocol [BGPW'13]:\n If $x=1$, Alice sets $A:=1$, otherwise picks a uniformly random $A\\in_U [0,1]$; If $y=1$, Bob sets $B:=1$, otherwise picks a uniformly random $B\\in_U [0,1]$; A continuous clock counts time $t$ from $0$ to $1$; If $A$ is reached, Alice raises her hand and the protocol terminates; If $B$ is reached, Bob raises his hand and the protocol terminates; If the protocol terminates at time $t\u0026lt;1$ output $AND(x,y)=0$; If the protocol terminates at time $t=1$ output $AND(x,y)=1$.  Note that the ascending clock \u0026ldquo;protocol\u0026rdquo; is not really a protocol, since it runs in continuous time. It can be approximated by an $r$-round protocol $\\pi_r$ with each step representing the clock running for $\\frac{1}{r}$ time units. The information cost of such $\\pi_r$ is $\\sim \\frac{1}{r^2}$ bits higher than optimal, which is only attained at the limit. Thus even for the two-bit AND function, optimal information complexity is only attained in the limit!\nBased on the optimality of the ascending clock protocol, one can get exact bounds on several two-party communication problems that are based on $n$ copies of the two-bit AND function:\n Intersection. The randomized communication complexity of finding the intersection of two subsets of $\\lbrace 1,\\ldots,n\\rbrace$ (which amounts to $n$ copies of AND) is $C_\\wedge \\cdot n \\pm o(n)$, where $C_\\wedge\\approx 1.4923$ is a constant obtained by maximizing an explicit function.  Interestingly, when no error is allowed, the constant increases to $\\log_2 3\\approx 1.585$ [AC'94].\n Disjointness. The randomized communication complexity of deciding whether two subsets of $\\lbrace 1,\\ldots,n\\rbrace$ intersect (which amounts to $n$ copies of AND where the prior $\\mu$ puts zero weight on $(1,1)$) is $C_{DISJ} \\cdot n \\pm o(n)$, where $C_{DISJ}\\approx 0.4827$.\n  Small set Disjointness The randomized communication complexity of deciding whether two subsets of $\\lbrace 1,\\ldots,n\\rbrace$ of size $k$ intersect (which amounts to $n$ copies of AND where the prior $\\mu$ puts zero weight on $(1,1)$ and $\\frac{k}{n}$ weight on the $(0,1)$ and $(1,0$ entries) is $\\frac{2}{\\ln 2} \\cdot k \\pm o(k)$.\n  In this case, even the fact that the communication complexity is $O(k)$ and not $O(k \\log k)$ is somewhat surprising [HW'07].\nDoes one need memory to approximately count? As discussed earlier, the strength of information-theoretic formalism is its ability to formalize vague statements about states of \u0026ldquo;knowledge\u0026rdquo; into precise (and correct) mathematical statements. Within complexity theory there are many examples of this from the last two decades. Let us highlight an easy-to-state recent example, motivated by streaming algorithms.\nAn algorithm is given access to a sequence $x_1,\\ldots,x_n$ of uniformly random bits. At the end, it needs to guess whether there were more $0$\u0026rsquo;s in the sequence or more $1$\u0026rsquo;s. The algorithm only needs to be correct on $51%$ of the inputs. This means that it is ok to only ouput $1$ on sequences with more than $\\frac{n}{2}+\\sqrt{n}$ $1$\u0026rsquo;s, output $0$ on sequences with more than $\\frac{n}{2}+\\sqrt{n}$ $0$\u0026rsquo;s, and give a random answer otherwise. The constrained resource is the amount of memory $S$ the algorithm can store while reading the stream.\nOne obvious solution is to maintain a register that at time $t$ stores $R_t=\\sum_{j=1}^t x_t$, and outputing $1$ if $R_n\u0026gt;n/2$. This solution requires memory $S=\\log n + O(1)$. Can one do substantially better? It turns out that the answer is tight:\nTheorem [BGW'20] Solving the approximate majority problem requires memory $S\\ge \\Omega(\\log n)$.\nNote that even though the theorem\u0026rsquo;s statement appears \u0026ldquo;obviously true\u0026rdquo;, it is more delicate than one would expect: (1) it is possible to distinguish sequences with $\\frac{n}{2}+n^{0.67}$ $1$\u0026rsquo;s from uniform sequences using only $O(\\log \\log n)$ memory; (2) it is possible to solve the problem using $O(\\log n)$ memory while only storing $O(1)$ information about the $x_j$\u0026rsquo;s seen so far. The relevant quantity which must be at least $\\Omega(\\log n)$ for a typical $t$ turns out to be:\n$$ \\sum_{j=1}^t I(R_t; X_j | R_{j-1}). $$\nOnce this quantity is correctly identified, the proof follows relatively standard proof patterns.\nBeyond two party communication? It is very interesting to consider the kinds of problems where information-theoretic reasoning has not been successful so far. It is natural to try the same approach for more than two parties. In a three-party setting one can define the information complexity of problems based on the amount of information the participants need to reveal to each other in order to solve the problem. It is not difficult to prove a direct sum theorem showing that the (3-party) information complexity of $k$ copies of a task $T$ are $k$ times the information complexity of a single copy. Unfortunately, such a statement turns out to be vacuous! Communication amoung 3 or more \u0026ldquo;honest-but-curious\u0026rdquo; parties supports information-theoretically secure multi-party computation, which means that any function can be computed by 3 or more parties without revealing anything to each other (except for the answer in the end). Thus the \u0026ldquo;direct sum\u0026rdquo; theorem in this case turns out to be of the form \u0026ldquo;$k\\times 0 = 0$\u0026rdquo;.\nThis pattern appears to repeat itself in any computational model that is rich enough to support information-theoretically secure computation. For example, consider communication over a channel where Alice and Bob each submit a bit $x_i$ and $y_i$, and learn the value $x_i\\wedge y_i$ of the AND of the two bits. Information-theoretic lower bounds over such a channel would have had interesting complexity-theoretic implications. Once again, one can redo information complexity over such a channel and obtain direct sum results. Once again, the result is vacuous, since such a channel is powerful enough to be able to implement information-theoretically secure two party computation [K'91]. The same is true in the context of Arthur-Merlin games [GPW'16].\nUnderstanding whether this is a surmountable technical barrier, or a true conceptual one (that requires new tools or even new conjectures) is a topic which I hope to work on in the future.\nFurther reading  A 15 minutes high level overview on theoretical computer science and information complexity: [pdf] A survey can be found here. Quantum information complexity is a very interesting topic not covered above. Some pointers can be found here and here. The papers section on this page.  "},{"id":7,"href":"/team/joining-the-group/","title":"Joining the group","parent":"Group","content":"Thank you for you interest in joining the group!\nUnfortunately, due to large volumes of email, I am not able to respond to individual inquiries about joining Princeton or our group. Some general details can be found below.\nHigh school and undergraduate students   If you are a Princeton undergrad, and are interested in the possibility of doing Junior/Senior independent work, please email me to make an appointment and discuss your interests. You can browse this page and look at the papers to get an idea of the topics we\u0026rsquo;re working on. Please also look at potential IW topics here.\n  I do not have internships for undergrads from outside Princeton. That said, truly exceptional undergrads (e.g. IMO/IOI medalists, top performance in Putnam, ACM programming world finalists, etc.) are welcome to contact me for potential opportunities.\n  Unfortunately, I do not have research opportunities for high school students.\n  If you have been admitted to the undergraduate program at Princeton, and are in the process of choosing between colleges and would like to meet, please send me an email. If you are considering or in the process of applying, I would prefer to wait until the admissions process runs its course before meeting. Note that I have no influence on the admissions decisions.\n  Prospective graduate students   We are recruiting outstanding graduate students!\n  If you are a current Princeton graduate student and would like to talk about the possibility of working with me, write me an email.\n  If you are not currently a graduate student at Princeton, you have to apply for admission first. More information can be found here. Please follow the procedure for applying. Please note that the selection of PhD students to be admitted is a competitive process based on the merits of individual applications.\n  You may also be interested in our funded Master\u0026rsquo;s program.\n  Emailing me does not improve your chances of being admitted. If anything, \u0026ldquo;mass\u0026rdquo; emails might slightly hurt your chances. If you are interested in working with me, please apply to the Theoretical Computer Science track and mention that you would like to work with me in your statement, and I will look at your file during the admissions process.\n  I cannot (nor am willing to try to) estimate your chances of being admitted to a graduate program in Princeton CS. The admissions process is complicated, and looks at a variety of factors in the application, including grades, personal statement, and recommendation letters.\n  If you feel that due to unusual circumstances your application is at a high risk for being overlooked, please have your academic adviser or senior program administrator send me a personal email.\n  Postdocs   We usually have a number of postdoc opportunities through the Theory Group, please see here.\n  If you feel that due to unusual circumstances your application is at a high risk for being overlooked, please have your PhD adviser send me a personal email.\n  "},{"id":8,"href":"/research/mech-design/","title":"Mechanism design","parent":"Research","content":" Black-box reductions from algorithms to mechanisms without money Strategic capitation: mechanism design in the \u0026ldquo;big data\u0026rdquo; regime Mechanism design for learning agents  Overview Algorithm design vs. mechanism design. The starting point of Algorithm design is a specified input-output behavior: $L$ is a list of numbers, and $SORT(L)$ is the same list sorted in ascending order; $f$ is boolean formula, and $SAT(f)$ is a satisfying assignment \u0026ndash; if one exists; $D$ is a list of labeled examples, and $Model(D)$ is a trained model for labeling previously unseed examples. Some of these tasks are incredibly complex. Much of computer science (and applied mathematics) is about finding new ways of performing these tasks. No matter how complex the algorithmic task at hand, it is normally assumed that the input $x$ does not depend on algorithm $A$.\nWhen the inputs to an algorithm $A$ come from outside parties interested in the output of the algorithm, this assumption breaks down. For example, underlying an auction is typically a simple optimization algorithm (with a single item for sale, the algorithm is just the $max$ function). However, inputs come from bidders who might (and will) optimize their bids to get an improved outcome (for example, get the item for as little money as possible). The field of mechanism design studies designing algorithms where the inputs are provided by self-interested (and potentially strategic) agents. Mechanism design draws on game theory for its modeling foundations. Algorithmic mechanism design specifically studies settings where both the algorithmic and game-theoreic aspects play an important role.\nWithin theoretical computer science, there are several reasons to study algorithmic mechanism design now. Algorithmic mechanism design is becoming more important as algorithms enter more application domains. Even in areas where the \u0026ldquo;algorithms\u0026rdquo; involved are fairly simple, the availability of data and cheap compute means that it is easy for participants to be more strategic. This means that systems design needs to incorporate mechanism design thinking. Ideally, a set of transformations and heuristics would make this process automatic or at least routine. On the other hand, algorithms (along with data and hardware) are evolving at a rapid rate, giving rise to exciting new opportunities for making systems better using mechanims that incorporate these algorithmic advances.\nWhile both mechanism design and algorithm design and deployment are progressing rapidly, algorithms are being developed and deployed at a faster rate. This leads to a growing gap between areas and ways in which algorithms are used and mechanism design theory and craft. My overall goal is to develop generic tool for narrowing this gap. In technical terms it means developing tools, techniques, and concepts for reductions from algorithms to mechanisms.\nBlack-box reductions from algorithms to mechanisms without money Mechanism design without money. Abstractly, mechanism design addresses the problem of aggregating preferences of multiple parties into an outcome. Examples of mechanisms include the housing market, voting, college admissions, and the electricity market. Mechanisms can be (roughly) partitioned into mechanisms with and without money. Of the examples above, the housing and electricity markets explicitly involve money, while voting and college admissions do not. Mechanism design without money is generally very challenging. Even the relatively “simple” case of voting is rife with impossibility results.\nThe VCG mechanism with money. Mechanism design with money is also challenging, but it admits several very general solution concepts, such as the celebrated Vickrey–Clarke–Groves mechanism. In one sentence the VCG mechanism can be summarized as “optimize outcome, charge each player their externality”. A player’s externality is the effect that player has on the welfare of the other players. For example, in the special case of a single-item auction, VCG becomes the second price auction: the winner deprives other players of the item, and their externality is the highest utility for the item among the remaining players. The VCG has some wonderful properties, including dominant-strategy truthfulness: players never benefit from misreporting their preferences. It also has some significant limitations. In addition to requiring money, the mechanism is quite unstable numerically, making it challenging to combine with heuristic algorithms.\nRepeated games vs. single shot. The main reason why mechanism design with money is “easier” than mechanism design without money, is that money essentially turns each game into a repeated game. Someone who doesn’t win in an auction, gets to keep their money for future use. It is much easier to sustain “good” behavior (such as truthful reporting) in a repeated game. Even without money, it is much easier to run a repeated mechanism by introducing a points currency. The currency will have no value outside of a repeated mechanism but can be used to connect rounds of the mechanism. For example, if we need to repeatedly allocate tasks to people, we can create a point system where less desirable tasks “pay” more points (with rates determined via a market-like mechanism), and where, over the long run, all participants are expected to “earn” the same number of points.\nContinuous optimization based on local search. Suppose we need to maximize a function $F(x)$ on some domain $\\mathcal{X}$. A surprisingly powerful approach is gradient descent: make a sequence of small local steps, each improving the value of $F$ slightly. This method is guaranteed to converge to a local maximum (and the global maximum when the global maximum is unique, such as when $F$ is concave). Gradient descent and its variants, such as stochastic gradient descent, play an important role in online learning, optimization, and machine learning model training. Motivated primarily by the latter application, these algorithms have seen a lot of activity, both in terms of theory and implementation. Most optimization algorithms can be recast in terms of a local gradient-based search. It should be noted that while the local procedure is typically quite simple, the overall algorithm here may be quite complicated, with a lot of effort going into tweaking the objective function (e.g. through regularization), step sizes (aka learning rates) and other meta-parameters.\nPutting the pieces together: a new optimization-to-mechanism reduction. We are given a gradient-descent-based optimization procedure, and wish to turn it into a mechanism that incentivizes participants to reveal their types truthfully. Our proposed APEX (Adaptive Pricing Equalizing Externalities) framework does it by applying VCG locally to each optimization step. This sidesteps two of the main difficulties of applying VCG in combination with optimization algorithms: (1) by making the steps local, the optimization problem becomes very simple, avoiding the sensitivity of VCG to heuristic errors; (2) by taking many small steps, the game becomes repeated, essentially turning the problem without money into one where money-like points are used across rounds.\nNew results. While the applied side of the framework will need to be validated experimentally, theoretical results have been very promising. Consider the setting of one-sided allocation without money, such as allocating students to school slots. This setting is “one-sided” because only one side of the match has preferences over the other side. There are $n$ participants that need to be allocated $n$ items – one item each. A classical result of Hylland and Zeckhauser (1979), showed that the allocation problem can be solved using a market-like mechanism called a competitive equilibrium from equal incomes (CEEI). Each item $j$ is assigned a price $P_j$; each player is give one unit of tokens. Each player “buys” her favorite distribution (fractional allocation) of items at prices $P_j$ without exceeding her budget. The [HZ79] results states that there are always market-clearing prices. Notably, these prices and allocations are known to not be uniquely determined by the players’ utilities.\nBy plugging in the one-sided allocation problem into the APEX framework, we obtain a sharpening of the [HZ79] result: there is a scaling of players’ utilities, such that if we run the unit-demand VCG auction with these scaled utilities, the resulting prices are HZ prices. Interestingly, this is a proper subset of all possible HZ prices/equilibria: there are HZ allocations that are not supported by any VCG prices.\nFurther reading:\n Preprint: [arXiv]  Strategic capitation: mechanism design in the \u0026ldquo;big data\u0026rdquo; regime The motivation for this work comes from pricing insurance reimbursement for Medicare Advantage, but it is part of a much broader challenge of adapting problems in classical mechanism design to the “big data” regime. Informally, the “big data” regime is a regime where mining data for information, while not infinitely useful, is still useful (so more data leads to better information).\nWe consider a scenario where a principal wishes to outsource the care of some patients to a private insurance plan. Let us say that the care of a patient $p$ costs $C_{pub}(p)$ in the public system, and $C_{priv}(p)$ under private insurance. Note that none of the costs are known a priori, and the best one can do is estimate them from known characteristics. The principal’s goal here is to achieve an efficient allocation. Simplifying, and assuming $C(p)$ accounts for quality as well as cost, an ideal mechanism would allocate $p$ to the private plan if $C_{priv}(p)\u0026lt;C_{pub}(p)$, and to the public plan otherwise. Patient costs are estimated using past cost data and patient characteristics.\nIf the principal could just allocate patients between the plans, it could produce the first-best allocation by estimating costs, and sending patients whose expected $C_{priv}(p)$ is lower than $C_{pub}(p)$ to the private plan. However, in reality, the principal is unable to just allocate patients. It writes a reimbursement contract, and then lets the private agent recruit patients: this is exactly how Medicare Advantage works. Therefore, the principal would like to design a contract that would cause the private agent to select patients if and only if $C_{priv}(p)\u0026lt;C_{pub}(p).$\nIf only little data were available about each patient, the number of patients $\\gg$ data dimension, and the principal could calculate a very accurate unbiased estimate $E(p)$ of $C_{pub}(p)$ given the data, and write $E(p)$ as the reimbursement. If the private agent also only has access to the same data, the only thing it can do is to produce an estimate of $C_{priv}(p)$, and select if it is lower than $C_{pub}(p)$. If, on the other hand, the private agent has access to more data, it can produce a better estimate of $C_{priv}(p)$, and exploit the principal by attracting patients with $$C_{pub}(p) \u0026lt; C_{priv}(p) \u0026lt; E(p).$$ For example, if reimbursement is set based on patient age, but the private plan has access to some health information, it can exploit the scheme by attracting older patients who are unusually healthy for their age.\nIf rich data on an unlimited number of patients were available, the principal could produce extremely accurate estimates $E_{rich}(p)$ of $C_{pub}(p)$ given the data, and write $E_{rich}(p)$ as the reimbursement. The richness assumption would guarantee that the private plan has no way of obtaining more accurate estimates, and that only selecting patients with $C_{priv}(p) \u0026lt; E_{rich}(p) \\approx C_{pub}(p)$ is the best response, leading to efficient selection. Here we rely crucially on having an unlimited number of patients to produce good estimates $E_{rich}$. If the private agent is able to use more data to produce better estimates, it will be able to again exploit the system as in the little data regime.\nIn practice, we are in what we call the big data regime – there is enough data to produce good cost estimates, but with more data and effort the private agent can refine these estimates and select over-reimbursed patients. This gap becomes more significant as data becomes high dimensional (so that even over millions of patients estimation errors are non-negligible), and advances in statistics and machine learning lead to better estimation techniques. To counter this problem, we propose a new class of strategic capitation mechanisms: instead of writing a contract in terms of a fixed formula $E(p)$ based on estimated public cost, we split the contract into two terms: (1) the first term is a fixed unbiased estimator based on few relevant characteristics as in the little data regime; (2) the second term is only calculated after selection is realized (e.g. at the end of the year), and accounts for all data available, as in the rich data regime. Importantly, for a private agent that does not actively engage in selection, the second term will be close to $0$. At the same time, since the second term is not revealed until after selection is realized, an agent who wishes to engage in strategic selection will not be able to use its statistical flaws to its advantage (since these flaws are only revealed after selection has already happened).\nMore broadly, the framework we propose allows a principal who is computationally weaker or has less data to use the time dimension to incentivize efficient behavior by more sophisticated agents. This is done by using the time dimension, revealing some of the contract ex-post. The ex-post part is such that simple agents are not affected by it. The ex-post contract, in expectation, has statistical properties which would be unattainable for a fixed ex-ante contract, ensuring that even sophisticated agents cannot exploit it.\nFurhter reading:\n Preprint: [NBER] Journal of Public Economics [paper]  Mechanism design for learning agents The main challenge algorithmic mechanism design aims to address is implementing algorithmically-optimal solutions in environments with self-interested parties. Classic algorithm design assumes that players are truthful (i.e. always reveal their true preferences and participate in the algorithm in prescribed ways). Classic game theory assumes that players best respond in equilibrium: that is, they take actions/reveal information to maximize their own utility. In most cases, there is a significant gap between what is attainable in a game-theoretic equilibrium, and what is attainable algorithmically (this gap is known as the price of anarchy).\nWhen the stakes are sufficiently high, ignoring incentives will lead to unraveling, and is not an option. On the other hand, without additional assumptions, it is often impossible to compute equilibria solutions of most games. The issue is not just computational complexity, but also the fact that information environments faced by individual players are often incomplete, and are hard to model.\nIn practice, this means that beyond designing mechanisms where non-strategic behavior always dominates strategic behavior, it is difficult to make use of equilibrium concepts to predict players’ behavior. In multi-round games (such as repeated auctions or procurement), a slightly weaker – but algorithmically much more friendly – model of players’ behavior is to assume that the players are learning to play. This is a realistic model of players’ behavior, especially since in many cases it is impossible to separate learning the environment from learning to strategically interact with it. For example, an algorithm optimizing an online ad campaign will use online learning to tweak “strategic” aspects of the campaign (such as how much to bid for ad placement) and “non-strategic” ones (such as optimizing ads to increase conversion).\nOnce we have an explicit model for players’ behavior based on online learning, we can obtain new insights in scenarios which would be out of reach for “standard” equilibrium analysis. We can also introduce new strategic scenarios (such as multi-arm bandits with strategic arms), which arise specifically when one side runs an online learning algorithm.\nPreliminary results show that mechanism design with learning agents indeed falls somewhere between non-strategic algorithm design and standard mechanism design based on Nash equilibria. For example, in “Selling to a no-regret buyer” we revisit the classical scenario of a seller (repeatedly) selling a single item to buyers drawn from a distribution. A classical theorem by Myerson characterizes the optimal revenue attainable with strategic buyers. Note that the maximum revenue attainable with non-strategic buyers is just the aggregate utility that the buyers get from the items. We show that if the buyers are learning to repeatedly bid in the auction using a low-regret algorithm (such as multiplicative weight update), the seller can extract significantly more revenue than Myerson’s mechanism (while also improving overall utility). At the same time, there is still a gap between what we can extract and the non-strategic optimal.\nPerhaps the best-studied online-learning scenario is that of multi-armed bandits, where the learner has to repeatedly select one of $k$ options, and only learns the reward of the selected option after it has been irrevocably selected. Multi-armed bandits (and their extensions to contextual bandits) capture much of the issues involved in online decision making. Examples range from repeatedly selecting a service contractor, to choosing which ads to display based on a query, to selecting a caching policy on a server. Importantly, in the classical bandit setting it is assumed that none of the parties are strategic.\nIn “Multi-armed bandit problems with strategic arms” we revisit the bandits model in the case where the arms are strategic. Consider the scenario where the learner needs to repeatedly hire a contractor to do a job. In this case, the goal of the learner is to always pick the best contractor in terms of $utility_t-cost_t$: the difference between its utility and its cost. When the utilities and costs are fixed (even adversarially), it is known from online learning theory (and practice) that this goal is attainable. However, if the “arms” are contractors, they will behave strategically to maximize their reward in the game. For example, they might misrepresent the cost in order to collect rewards in later rounds; a contractor may charge a very low fee to steer the learner away from competition, and then raise the prices in later rounds. Additionally, tacit collusion may emerge between the arms.\nBoth projects above demonstrate that applying “learning” to strategic problems is fraught even when the underlying learning problem is well-understood: whenever one party is learning, other parties may exploit it by “teaching” it to behave in their interest.\nFurther reading:\nNote: This is a very active research area, I will post a link to a survey sometime in the future.\n \u0026ldquo;Multi-armed bandit problems with strategic arms\u0026rdquo; [COLT'19] \u0026ldquo;Selling to a no-regret buyer\u0026rdquo; (EC'18); [arXiv] A 2019 survey on multi-arm bandits by Aleksandrs Slivkins: [arXiv]  "},{"id":9,"href":"/research/past-projects/","title":"Misc projects","parent":"Research","content":"Contents  New bounds on the Grothendieck constant Monotonicity and implementability  New bounds on the Grothendieck constant Let $A$ be an $n\\times n$ matrix. It gives rise to the quadratic form $$\\sum_{i,j} A_{ij} x_i y_j.$$ The Grothendieck constant $k$ bounds the ratio between the maximum of this form when $x_i,y_j$ are unit vectors in a Hilbert space and the maximum of this form when $x_i,y_j\\in {-1,1}$ are just real numbers. In other words, $k$ is the smallest number such that for all $A$,\n$$\\left|\\max_{||X_i||,||Y_j||\\leq 1} A_{ij} \\langle X_i, Y_j \\rangle\\right| \\leq k\\cdot \\left|\\max_{x_i,y_j\\in {-1,1}} A_{ij} x_i y_j\\right|.$$\nAlgorithmically, the Grothendieck constant can be viewed as the integrality gap between what can be attained by a general (vector) solution and the integral solution to the optimization problem of maximizing $\\sum_{i,j} A_{ij} x_i y_j$. A natural strategy for giving an upper bound on $k$ is to come up with a (possibly randomized) _rounding scheme_ that converts vectors $X_i, Y_j$ into numbers $x_i,y_j$ while losing a factor of at most $k$ in the objective function.\nRounding vectors to numbers has had many important applications in algorithms. For example, the Goemans-Williamson MAX CUT approximation algorithm represents the MAXCUT instance as a (tractable) optimization problem over vectors, and then uses a random projection onto a line to obtain an approximate integral solution. The approximation ratio is exactly the worst-case ratio between the value attained by the vector solution versus the integral solution.\nIn 1977, Krivine proposed a natural rounding scheme for the Grothendieck inequality, proving an upper bound $k\\le c_k= \\frac{\\pi}{2\\ln (1+\\sqrt{2})}\\approx 1.7822$, which he conjectured to be tight. The scheme (similarly to the rounding schemes in the algorithms from decades to follow), involved transforming the vectors and then applying a random projection of the vectors to a line (with vectors projected to the positive side assigned a $+1$, and those to the negative side a $-1$). In 2011 we disproved Krivine\u0026rsquo;s conjecture that $k=c_k$ by showing that $k\u0026lt;c_k$.\nThis is done by devising a better rounding scheme (or, rather showing that one exists via a delicate perturbation argument). In the process, we show that, most likely, a two-dimensional rounding strategy can beat the one dimensional strategy of projecting vectors onto a line. The two-dimensional strategy would partition the plane into two regions $R_{+1}$ and $R_{-1}$, and map vectors to numbers by projecting them to the plane and then assigning them to $\\pm 1$ based on the region into which they fall. The one-dimensional strategy corresponds to $R_{+1}$ and $R_{-1}$ each being a half-plane.\nThe diagram on the right gives an educated guess on what the partition of the plane $\\mathbb R^2$ might look like for the optimal two-dimensional Krivine scheme. If Krivine\u0026rsquo;s conjecture were true, the optimal partition would have been just a half-plane.\nReference: Mark Braverman, Konstantin Makarychev, Yury Makarychev, Assaf Naor. The Grothendieck constant is strictly smaller than Krivine\u0026rsquo;s bound, 2011.\nLinks: paper on arXiv; FOCS'11 version from IEEE; open access version from Forum of Mathematics, Pi.\nMonotonicity and implementability Consider an environment with a finite set of alternatives $A_1,\\ldots,A_k$ and agents who have quasi-linear preferences. That is, each agent $i$ has utility $u_{ij}$ for alternative $A_j$, and if she has to pay an amount $p_i$ her utility becomes $u_{ij}-p_i$. A direct mechanism consists of an allocation rule $f$ and payment rule $p$. The allocation rule maps each profile of valuations to a probability vector over the set of possible alternatives. For example, the second price auction on one item amounts to the allocation rule being “the highest bidder gets the item”, and the payment collected from the winner equals the second-highest bid (and no payment collected from other players).\nAn allocation rule $f$ is said to be implementable if there exists a payment rule $p$ so it is safe for each agent to report his true valuation to the mechanism $(f,p)$\u0026quot;) regardless of the reports of all other agents. In other words, the payment rule $p$ makes truthful reporting a dominant strategy for all players. Understanding which allocation rules are implementable is a fundamental concern in mechanism design. Myerson has shown in his seminal 1981 paper, that when the set of alternatives is single dimensional (for example when a single item is auctioned for sale), an allocation rule is implementable if an only if it is monotone in the valuation of a player. Informally, monotonicity means that higher demand for an outcome by a player will result in a greater-or-equal allocation of that outcome.\nFor multidimensional settings, such as selling multiple goods, Rochet has shown in 1987 that a stronger condition, called cycle-monotonicity, of an allocation rule is a necessary and sufficient condition for implementing it. Cyclic monotonicity however is a considerably more difficult condition to work with than monotonicity. Monotonicity is a condition on every pair of values, whereas cyclic monotonicity is a condition on every finite sequence of values. This gives rise to the natural question of when does monotonicity imply cycle-monotonicity (and thus implementability).\nSaks and Yu (2005) have shown that when the domain of (multidimensional) valuations is convex, monotonicity is necessary and sufficient for implementing an allocation rule. We show that convexity is also necessary in the following sense: if the domain of valuation is not convex, there always exists an allocation rule that is monotone yet not implementable. In other words, when the domain of possible valuations is not convex, local constraints alone are not sufficient to guarantee implementability.\nFor each non-convex domain, the proof involves the construction of an allocation rule that is not implementable. The figure on the left shows a component of the proof for dimensions 3 and higher.\nReference: Itai Ashalgi, Mark Braverman, Avinatan Hassidim, Dov Monderer. Monotonicity and Implementability, Econometrica, 78(5), 2010.\nLinks: Econometrica 78(5), 2010; [pdf] [Supplementary material]\n"},{"id":10,"href":"/about/funding/","title":"Funding","parent":"About","content":"I gratefully acknowledge the following funding sources: Present:  NSF, through the Alan T. Waterman award CCF-1933331 The Simons Foundation, through the Simons Collaboration on Algorithms and Geometry The David and Lucile Packard Foundation, through a Packard Fellowship  Past:  NSF, through award CCF-1525342: \u0026ldquo;Noise across computational settings\u0026rdquo; Princeton University, through an Alfred Rheinstein Faculty Award NSF, through CAREER award CCF-1149888: \u0026ldquo;Coding and information theory for interactive computing\u0026rdquo; NSF, through award CCF-1215990: \u0026ldquo;Collaborative Research: Data-driven mechanisms in healthcare\u0026rdquo; (joint with Mohsen Bayati from Stanford) The John Templeton Foundation, through a Turing Fellowship, which was part of \u0026ldquo;The Turing Centenary Research Project - Mind, Mechanism and Mathematics\u0026rdquo; NSF, through the Center for Computational Intractability The Alfred P. Sloan Foundation, through a Sloan Research Fellowship NSERC, through a Discovery Grant \u0026ldquo;Complexity theory, algorithms and applications\u0026rdquo; (while at the University of Toronto).  "},{"id":11,"href":"/team/postdoc-opportunities/","title":"Postdoc opportunities","parent":"Group","content":"We have several exciting postdoctoral opportunities in Princeton and the area.\nPrinceton CS Theory group: Please see Princeton academic jobs portal here, and navigate to opportunities in Computer Science. The Theory Group typically advertises a postdoctoral research associate position and an associate research scholar position, which is slightly more senior. Both positions are reviewed in the late Fall, with the goal of making decisions by January/February.\nIAS Membership: More information here.\nDIMACS programs More information here\n"},{"id":12,"href":"/research/writings/","title":"Writings","parent":"Research","content":"An essay on the need for personal digital advocates (Last updated: December 2020)\nAbstract: There is a growing power imbalance between companies who have access to powerful algorithms and processing capacity and users who don’t. To restore the balance, we need to put equally powerful algorithms in the hands of individuals. There are two concrete steps we recommend:\n(1) there should be a new regulatory framework which creates an unbreakable commitment for an advocate (a digital service) to work exclusively in the interest of its client;\n(2) existing and new regulations around digital rights of individuals (such as GDPR) should make it a priority to make it easy for users to take advantage of these rights using software.\nFull essay: [pdf]\n"},{"id":13,"href":"/research/all-papers/","title":"All Papers","parent":"Research","content":"Selected recent publications and preprints   Optimization-friendly generic mechanisms without money\nMark Braverman\n[arXiv]\n  Statistically near-optimal hypothesis selection\nOlivier Bousquet, Mark Braverman, Klim Efremenko, Gillat Kol, Shay Moran\nFOCS'21; [arXiv]\n  Tight space complexity of the coin problem\nMark Braverman, Sumegha Garg, Or Zamir\nFOCS'21; [ECCC]\n  Data-driven incentive alignment in capitation schemes\nMark Braverman, Sylvain Chassang\n[NBER preprint] [Journal of Public Economics 207, 2022]\n  BeauCoup: Answering many network traffic queries, one memory update at a time\nXiaoqi Chen, Shir Landau-Feibish, Mark Braverman, Jennifer Rexford\n[SIGCOMM'20]; [APNIC post]\n  The role of randomness and noise in strategic classification\nMark Braverman, Sumegha Garg\nFORC'20; [arXiv]; [youtube talk]\n  Space-Bounded Church-Turing Thesis and computational tractability of closed systems\nMark Braverman, Cristobal Rojas, Jon Schneider\nPhys. Rev. Lett. 115, 098701; [link] [phys.org article]\n  Interactive information and coding theory\nMark Braverman\nA survey accompanying an invited lecture at ICM'14 in Seoul [pdf]\nVideo of the talk [youtube]\n  Interactive information complexity\nMark Braverman\nSTOC'12; [ECCC]; [SICOMP 64(6)]; [SIAM Review 59(4)]\n  The Grothendieck constant is strictly smaller than Krivine\u0026rsquo;s bound\nMark Braverman, Konstantin Makarychev, Yury Makarychev, Assaf Naor\nFOCS'11; [arXiv] [Forum of Mathematics, Pi version]\n  Other publications   Unbiased delay measurement in the data plane\nYufei Zheng, Xiaoqi Chen, Mark Braverman, Jennifer Rexford\n[APOCS'22]\n  An invariance principle for the multi-slice, with applications\nMark Braverman, Subhash Khot, Noam Lifshitz, Dor Minzer\nFOCS'21; [arXiv]; [youtube talk]\n  Near-optimal distributed learning of halfspaces with two parties\nMark Braverman , Gillat Kol , Shay Moran , Raghuvansh R. Saxena\n[COLT'21]\n  New separations results for external information\nMark Braverman, Dor Minzer\nSTOC'21; [arXiv]; [youtube talk]\n  Optimal tiling of the Euclidean space using permutation-symmetric bodies\nMark Braverman, Dor Minzer\n[Complexity'21]; [public talk related to this paper]\n  Prior-free dynamic mechanism design with limited liability\nMark Braverman, Jon Schneider, Matt Weinberg\nEC'21; [arXiv]\n  Tiered random matching markets: rank is proportional to popularity\nItai Ashlagi, Mark Braverman, Amin Saberi, Clayton Thomas, Geng Zhao\n[ITCS'21]; [youtube talk]\n  On rich $2$-to-$1$ games\nMark Braverman, Subhash Khot, Dor Minzer\n[ITCS'21]; [youtube talk]\n  Clearing matching markets efficiently: informative signals and match recommendations\nItai Ashlagi, Mark Braverman, Yash Kanoria, Peng Shi\nManagement Science 66(5), 2020 (earlier version in EC'17)\n[Management Science]; [SSRN]; [youtube talk]\n  The coin problem with applications to data streams\nMark Braverman, Sumegha Garg, David Woodruff\nFOCS'20; [ECCC]; [youtube talk]\n  Calibration, entropy rates, and memory in language models\nMark Braverman, Xinyi Chen, Sham Kakade, Karthik Narasimhan, Cyril Zhang, Yi Zhang [ICML'20]\n  The gradient complexity of linear regression\nMark Braverman, Elad Hazan, Max Simchowitz, Blake Woodworth\n[COLT'20]\n  Optimal short-circuit resilient formulas\nMark Braverman, Klim Efremenko, Ran Gelles, Michael A. Yitayew\n[Complexity'19]\n  On the computational power of radio channels\nMark Braverman, Gillat Kol, Rotem Oshman, Avishay Tal\n[DISC'19]\n  Multi-armed bandit problems with strategic arms\nMark Braverman, Jieming Mao, Jon Schneider, S. Matthew Weinberg\n[COLT'19]\n  Sorted Top-k in rounds\nMark Braverman, Jieming Mao, Yuval Peres\n[COLT'19]\n  Reliable communication over highly connected noisy networks\nNoga Alon, Mark Braverman, Klim Efremenko, Ran Gelles, Bernhard Haeupler\nDistributed Computing, 32(6), 2019; also PODC'16\n[ECCC]; [Distributed Computing]\n  The price of uncertain priors in source coding\nMark Braverman, Brendan Juba\nIEEE Transactions on Information Theory, 65(2), 2019\n[Transactions on Information Theory]; [arXiv]\n  Information complexity and applications\nMark Braverman Japanese Journal of Mathematics 1(14), 2019\n[JJM]\n  Hitting sets with near-optimal error for read-once branching programs\nMark Braverman, Gil Cohen, Sumegha Garg\nSTOC'18, [ECCC], [SICOMP version]\n  Interactive compression to external information\nMark Braverman, Gillat Kol\n[STOC'18];\n  Selling to a no-regret buyer\nMark Braverman, Jieming Mao, Jon Schneider, Matt Weinberg\nEC'18; [arXiv]; Best Full Paper award\n  Semi-direct sum theorem and nearest neighbor under $\\ell_\\infty$\nMark Braverman, Young Kun Ko\n[APPROX'18]\n  A candidate for a strong separation of information and communication\nMark Braverman, Anat Ganor, Gillat Kol, Ran Raz\n[ITCS'18]\n  Information value of two-prover games\nMark Braverman, Young Kun Ko\n[ITCS'18]\n  On simultaneous two-player combinatorial auctions\nMark Braverman, Jieming Mao, Matt Weinberg\nSODA'18; [arXiv]\n  Constant-rate coding for multiparty interactive communication is impossible\nMark Braverman, Klim Efremenko, Ran Gelles, Bernhard Haeupler\nJournal of the ACM 65(1):4, 2018; (also STOC'16)\n[ECCC]; [JACM]\n  Nash equilibria in perturbation-stable games\nMaria-Florina Balcan, Mark Braverman\nTheory of Computing, 13(13), 2017\n[ToC]\n  A rounds vs. communication tradeoff for multi-party set disjointness\nMark Braverman, Rotem Oshman\n[FOCS'17]\n  Network coding in undirected graphs is either very helpful or not helpful at all\nMark Braverman, Sumegha Garg, Ariel Schvartzman\nITCS'17; [arXiv]\n  A discrepancy lower bound for information complexity\nMark Braverman, Omri Weinstein\nAlgorithmica 76(3), 2016; RANDOM'12; [Algorithmica]; [arXiv]\n  List and unique coding for interactive communication in the presence of adversarial noise\nMark Braverman, Klim Efremenko\nSICOMP 46(1) (special issue for FOCS'14)\n[SICOMP] [ECCC]\n  Tight space-noise tradeoffs in computing the ergodic measure\nMark Braverman, Cristobal Rojas, Jon Schneider\nMatematicheskii Sbornik, 208(12), 2017 (Special 150th anniversary issue)\n[Sbornik] [arXiv]\n  Parallel algorithms for select and partition with noisy comparisons\nMark Braverman, Jieming Mao, Matt Weinberg\nSTOC'16; [arXiv]\n  Interpolating between truthful and non-truthful mechanisms for combinatorial auctions\nMark Braverman, Jieming Mao, Matt Weinberg\nSODA'16; [arXiv]\n  Optimal Provision-After-Wait in healthcare\nMark Braverman, Jing Chen, Sampath Kannan\nMathematics of Operations Research 41(1), 2016; ITCS'14; [pdf]; [MOR]\n  Coding for interactive communication correcting insertions and deletions\nMark Braverman, Ran Gelles, Jieming Mao, Rafail Ostrovsky\nIEEE Transactions on Information Theory, 63(10), 2017 ; ICALP'16;\n[Transactions on Information Theory]; [arXiv]\n  Communication lower bounds for statistical estimation problems via a distributed data processing inequality\nMark Braverman, Ankit Garg, Tengyu Ma, Huy Nguyen, David Woodruff\nSTOC'16; [arXiv]\n  Near-optimal bounds on bounded-round quantum communication complexity of disjointness\nMark Braverman, Ankit Garg, Young Kun Ko, Jieming Mao, Dave Touchette\nSIAM Journal on Computing 47(6), 2018 (special issue for FOCS'15)\n[ECCC]; [SICOMP]\n  ETH hardness for Densest-k-Subgraph with perfect completeness\nMark Braverman, Young Kun Ko, Aviad Rubinstein, Omri Weinstein\nSODA'17; [ECCC]\n  Information complexity is computable\nMark Braverman, Jon Schneider\nICALP'16; [ECCC]\nVideo of talk given at the Simons Institute [youtube]\n  The communication complexity of Number-In-Hand Set Disjointness with no promise\nMark Braverman, Rotem Oshman\nPODC'15; [ECCC]\n  Simulating noisy channel interaction\nMark Braverman, Jieming Mao\nITCS'15; [ECCC]\n  Small value parallel repetition for general games\nMark Braverman, Ankit Garg\nSTOC'15; [ECCC]\n  Approximating the best Nash equilibrium in -time breaks the Exponential Time Hypothesis\nMark Braverman, Young Kun Ko, Omri Weinstein\nSODA'15; [ECCC]\n  An interactive information odometer with applications\nMark Braverman, Omri Weinstein\nSTOC'15; [ECCC]\n  The computational hardness of pricing compound options\nMark Braverman, Kanika Pasricha\nworking paper; ITCS'14; [ECCC]\n  A hard-to-compress interactive task?\nMark Braverman\nAllerton'13; [pdf]\n  Public vs private coin in bounded-round information\nMark Braverman, Ankit Garg\nICALP'14; [ECCC]\n  Tight bounds for set disjointness in the message passing model\nMark Braverman, Faith Ellen, Rotem Oshman, Toniann Pitassi, Vinod Vaikuntanathan\nFOCS'13; [arXiv]\n  Direct products in communication complexity\nMark Braverman, Anup Rao, Omri Weinstein, Amir Yehudayoff\nFOCS'13; [ECCC]\n  From information to exact communication\nMark Braverman, Ankit Garg, Denis Pankratov, Omri Weinstein\nSTOC'13; [ECCC]\n  Direct product via round-preserving compression\nMark Braverman, Anup Rao, Omri Weinstein, Amir Yehudayoff\nICALP'13; [ECCC]\n  Information lower bounds via self-reducibility\nMark Braverman, Ankit Garg, Denis Pankratov, Omri Weinstein\nCSR'13; [ECCC]\nJournal of Computing Systems [Springer]\n  Search using queries on indistinguishable items\nMark Braverman, Gal Oshri\nSTACS'13; [arXiv]\n  On the convergence of the Hegselmann-Krause system\nArnab Bhattacharyya, Mark Braverman, Bernard Chazelle, Huy Nguyen\nITCS'13; [arXiv]\n  An information complexity approach to extended formulations\nMark Braverman, Ankur Moitra\nSTOC'13; [ECCC]\n  Coding for interactive computation: progress and challenges\nMark Braverman\nAllerton'12; [pdf]\n  Towards deterministic tree code constructions\nMark Braverman\nITCS'12; [ECCC]\n  Noise vs computational intractability in dynamics\nMark Braverman, Alexander Grigo, Cristobal Rojas\nITCS'12; [arXiv]\n  Towards coding for maximum errors in interactive communication\nMark Braverman, Anup Rao\nSTOC'11; [ECCC] [video by Anup]\n  Information equals amortized communication\nMark Braverman, Anup Rao\nFOCS'11; [ECCC]\nIEEE Transactions on Information Theory, 60(10), 2014 [[IEEE](https://ieeexplore.ieee.org/document/6877708)\n  Leaky pseudo-entropy functions\nMark Braverman, Avinatan Hassidim, Yael Tauman Kalai\nIn ITCS'11; [pdf]\n  Finding endogenously formed communities\nMaria-Florina Balcan, Christian Borgs, Mark Braverman, Jennifer Chayes, Shang-Hua Teng\nSODA'13; [arXiv]\n  Truthful mechanisms for competing submodular processes\nAllan Borodin, Mark Braverman, Brendan Lucier, Joel Oren\nWWW'13; [arXiv]\n  Inapproximability of NP-complete variants of Nash equilibrium\nPer Austrin, Mark Braverman, Eden Chlamtac\nin APPROX'11; [arXiv]\nTheory of Computing, 9(3), 2013.\n  Pseudorandom Generators for Regular Branching Programs\nMark Braverman, Anup Rao, Ran Raz, Amir Yehudayoff\n[SICOMP 43(3)], 2014;\nEarlier version in FOCS'10; [ECCC] [video by Anup]\n  Computability of Brolin-Lyubich measure\nIlia Binder, Mark Braverman, Cristobal Rojas, Michael Yampolsky\nIn Comm. in Math. Phys.; [arXiv]\n  The rate of convergence of the Walk on Spheres Algorithm\nIlia Binder, Mark Braverman\nGeometric and Functional Analysis22 (2012); [pdf]; [GAFA]\n  Thurston equivalence to a rational map is decidable\nSylvain Bonnot, Mark Braverman, Michael Yampolsky\nMoscow Math. Journal 12(4), 2012; [arXiv]; [MMJ]\n  How to compress interactive communication\nBoaz Barak, Mark Braverman, Xi Chen, Anup Rao\n[SICOMP 42(3)], 2013 (special issue for STOC'10);\nSTOC'10 [pdf]; [ECCC]\n  Stability in large matching markets with complementarities\nItai Ashalgi, Mark Braverman, Avinatan Hassidim\nOperations Research 62(4), 2014; [OR]; [pdf]\n  Phylogenetic Reconstruction with Insertions and Deletions\nAlex Andoni, Mark Braverman, Avinatan Hassidim\nWorking paper [pdf]\n  Monotonicity and Implementability\nItai Ashalgi, Mark Braverman, Avinatan Hassidim, Dov Monderer\nEconometrica 78(5), 2010; [pdf] [Supplementary material]\n  Sorting from Noisy Information\nMark Braverman, Elchanan Mossel\n[arXiv]\n  Ascending unit demand auctions with budget limits\nItai Ashalgi, Mark Braverman, Avinatan Hassidim\nWorking paper; [pdf]\n  Position Auctions with Budgets: Existence and Uniqueness\nItai Ashalgi, Mark Braverman, Avinatan Hassidim, Ron Lavi, Moshe Tennenholtz\nThe B.E. Journal of Theoretical Economics (Advances), 10(1), Article 20, 2010; [pdf].\n  Poly-logarithmic independence fools AC0 circuits\nMark Braverman\nComplexity'09; [ECCC]\nJournal of the ACM 57(5), 2010\nCommunications of the ACM, research highlight, 54(4), 2011\nLecture video from the 2011 METRIC workshop (audio quality not great): [video]\n  Finding low error clusterings\nNina Balcan, Mark Braverman\nCOLT'2009; [pdf]\n  The complexity of simulating Brownian Motion\nIlia Binder, Mark Braverman\nSODA'09; [pdf]\n  Constructing Locally Connected Non-Computable Julia Sets\nMark Braverman, Michael Yampolsky\nCommun. Math. Physics, 291(2), 2009; [pdf]\n  Space-Efficient Counting in Graphs on Surfaces\nMark Braverman, Raghav Kulkarni, Sambuddha Roy\nComputational Complexity 18(4), 2009; [pdf]\n  Pebbles and branching programs for tree evaluation\nStephen Cook, Pierre McKenzie, Dustin Wehr, Mark Braverman, Rahul Santhanam\nACM Transactions on Computation Theory (TOCT) 3(2), 2012; [arXiv]\nPreliminary version: MFCS'09 and FSTTCS'09\nSlides from Steve Cook\u0026rsquo;s talk with a \\$100 prize offer [pdf]\n  Book: Computability of Julia Sets\nMark Braverman, Michael Yampolsky\nSpringer, 2009.\n  Noisy Sorting Without Resampling\nMark Braverman, Elchanan Mossel\nSODA'08.\n  Mafia : a theoretical study of players and coalitions in a partial information environment\nMark Braverman, Omid Etesami, Elchanan Mossel\nAnnals of Appl. Prob. 18(3), 2008; [arXiv]\n  On ad hoc routing with guaranteed delivery\nMark Braverman\nBrief announcement, PODC'08; [arXiv]\n  The complexity of properly learning simple concept classes\nMisha Alekhnovich, Mark Braverman, Vitaly Feldman, Adam Klivans, Toniann Pitassi\nJournal of Computer and System Sciences, 74(1), 2008; [pdf]\n  Computability of Julia Sets\nMark Braverman, Michael Yampolsky\nMoscow Math. Journal 8(2), 2008; arXiv\n  Derandomizing Euclidean random walks\nIlia Binder, Mark Braverman\nRANDOM'07; [pdf]\n  Constructing Non-Computable Julia Sets\nMark Braverman, Michael Yampolsky\nSTOC'07; [pdf]\n  Parity Problems in Planar Graphs\nMark Braverman, Raghav Kulkarni, Sambuddha Roy\nComplexity'07; [pdf]\n  Filled Julia sets with empty interior are computable\nIlia Binder, Mark Braverman, Michael Yampolsky\nJournal of Found. of Comp. Math. 7(4), 2007; [arXiv]\n  On computational complexity of Riemann mapping\nIlia Binder, Mark Braverman, Michael Yampolsky\nArkiv for Matematik, 45(2), 2007; [arXiv]\n  Termination of Integer Linear Programs\nMark Braverman\nCAV'06 (Computer-Aided Verification); [pdf]\n  Non-Computable Julia Sets\nMark Braverman, Michael Yampolsky\nJourn. Amer. Math. Soc. 19(3), 2006; [arXiv]\n  Computing over the Reals: Foundations for Scientific Computing\nMark Braverman, Stephen Cook\nNotices of the AMS, 53(3), March 2006; [arXiv]\n  Parabolic Julia Sets are Polynomial Time Computable\nMark Braverman\nNonlinearity 19, 2006; [arXiv]\n  On computational complexity of Siegel Julia sets\nIlia Binder, Mark Braverman, Michael Yampolsky\nCommun. Math. Physics, 264(2), 2006; [arXiv]\n  On the Complexity of Real Functions\nMark Braverman\nFOCS'05 [pdf]\nFull version [arXiv]\n  Learnability and Automatizability\nMisha Alekhnovich, Mark Braverman, Vitaly Feldman, Adam Klivans, Toniann Pitassi\nFOCS'04; [pdf]\n  Hyperbolic Julia sets are poly-time computable\nMark Braverman\nCCA'04 (Computability and Complexity in Analysis), ENTCS 120; [pdf]\n  Other Manuscripts   Computational Complexity of Euclidean Sets: Hyperbolic Julia Sets are Poly-Time Computable\nMark Braverman\nMSc Thesis [pdf]\n  Computability and complexity of Julia sets\nMark Braverman\nPhD Thesis\n  Health care policy development and execution\nMohsen Bayati, Mark Braverman, Eric Horvitz, Michael Gillam\nUS patent application 20120004925; [USPTO]\n  Dispensing digital objects to an electronic wallet\nPhilipp Hertel, Alex Hertel, John Graham, Mark Braverman\nUS patent application 20110145049; [USPTO]\n  Secured electronic transaction system\nPhilipp Hertel, Alex Hertel, John Graham, Mark Braverman\nUS patent application 20090288012 [USPTO]\n  Predicting web advertisement click success by using head-to-head ratings\nMohsen Bayati, Mark Braverman, Satyen Kale, Yury Makarychev\nUS patent application 20100198685; [USPTO]\n  Method of registering and aligning multiple images\nVyacheslav Zavadsky, Jason Abt, Mark Braverman, Edward Keyes, Vladimir Martincevic\nSemiconductor Insights Inc.\nUS patent 7,693,348 [USPTO]\n  "},{"id":14,"href":"/research/","title":"Research","parent":"Mark Braverman","content":""},{"id":15,"href":"/team/","title":"Group","parent":"Mark Braverman","content":""},{"id":16,"href":"/team/undergraduate-projects/","title":"Undergraduate projects","parent":"Group","content":"2015-16:  Esther Rolf \u0026lsquo;16, Thesis, \u0026ldquo;Capturing multiparty communication: extending notions of information theory to topology-dependent multiparty problems\u0026rdquo; Michael Yitayew \u0026lsquo;16, Thesis, \u0026ldquo;Short-circuit error resilience in Boolean formulas\u0026rdquo; Zhongxia (Ricky) Zhao \u0026lsquo;16, Thesis, \u0026ldquo;Non-clearing and combinatorial Walrasian equilibria\u0026rdquo; Clement Lee \u0026lsquo;17, F15, \u0026ldquo;Fast polynomial factorization\u0026rdquo; Blair Wang \u0026lsquo;17, F15, \u0026ldquo;Discovery of spurious statistical relationships\u0026rdquo;  2014-15:  David Durst \u0026lsquo;15, Thesis, \u0026ldquo;Beyond3D: Visualizing high-dimensional data sets\u0026rdquo; James Pinkerton \u0026lsquo;15, Thesis, \u0026ldquo;Energy function arguments in finding Tower of Majority lower bounds\u0026rdquo;  2013-14:  Andra Constantinescu \u0026lsquo;14, Thesis, \u0026ldquo;Behavioral mechanism design - accounting for the mental cost of choosing\u0026rdquo; Mihai Roman \u0026lsquo;14, Thesis, \u0026ldquo;Computational complexity of pricing derivatives\u0026rdquo; Leonardo Stedile \u0026lsquo;14, Thesis, \u0026ldquo;Primal-dual based weights and other kidney exchange mechanisms\u0026rdquo; Valentina Barboy \u0026lsquo;15, F13, \u0026ldquo;An exploration of the accuracy and efficiency of peer grading\u0026rdquo; Stefani Karp \u0026lsquo;15, S14, \u0026ldquo;Information-theoretic approaches to the Unexpected Hanging Paradox\u0026rdquo; Christoph Schlom \u0026lsquo;15, S14, \u0026ldquo;Calibration testing\u0026rdquo;  2012-13:  Kevin Mantel \u0026lsquo;13, Thesis, \u0026ldquo;Election manipulation through misrepresentation of pre-election polls\u0026rdquo; Gal Oshri \u0026lsquo;13, Thesis, \u0026ldquo;Contracting experts with unknown cost structures\u0026rdquo; Kanika Pasricha, Thesis, \u0026ldquo;The computational hardness of pricing compound securities\u0026rdquo; Ashish Gupta \u0026lsquo;13, F12, \u0026ldquo;An investigation of the usefulness of data preprocessing techniques versus algorithmic sophistication on diabetes prediction\u0026rdquo; Leonardo Stedile \u0026lsquo;14, F12, \u0026ldquo;Analysis of risk in chess\u0026rdquo; Xiao Tian (Elaine) Liew \u0026lsquo;14, F12, \u0026ldquo;Effect of network structure on PageRank of spam\u0026rdquo; Xin Yang Yak \u0026lsquo;14, S13, \u0026ldquo;Do YouTube users upvote Better Comments? An analysis of the influence of spelling on comment ratings\u0026rdquo;  2011-12:  Michael Zhu \u0026lsquo;13, S12, \u0026ldquo;Finding overlapping communities in graphs\u0026rdquo; Gal Oshri \u0026lsquo;13, S12, \u0026ldquo;Search on multiple indistinguishable items\u0026rdquo; Rafael Grinberg \u0026lsquo;12, S12, \u0026ldquo;The effects of noise on cellular automata\u0026rdquo;  "},{"id":17,"href":"/","title":"Mark Braverman","parent":"","content":"\nI am a professor at the Department of Computer Science at Princeton University.\nMy office is 304 in CS Building (see campus map here).\nMy brief bio can be found here.\nI am interested in complexity theory, information theory, the theory of real computation, machine learning, algorithms, algorithmic mechanism design, and its applications.\nMy e-mail address: #######@cs.princeton.edu, replacing ####### with mbraverm.\n  Recent and current program committees (since 2021): ITCS'22 (program committee chair)\nPapers All papers\nHighlighted papers  Optimization-friendly generic mechanisms without money [arXiv]  Teaching  Spring 2022: COS445 Economics and computation Fall 2021: COS521 Advanced algorithm design  "},{"id":18,"href":"/posts/math-enabled/","title":"Math has been enabled","parent":"News","content":"Math is now enabled:\nInline math: $\\varphi = \\dfrac{1+\\sqrt5}{2}= 1.6180339887…$; or\nBlock math:\n$$ \\varphi = 1+\\frac{1} {1+\\frac{1} {1+\\frac{1} {1+\\cdots} } } $$\n"},{"id":19,"href":"/posts/new-website/","title":"New Website","parent":"News","content":"I created my new website using Hugo and GeekDocs!\n"},{"id":20,"href":"/categories/","title":"Categories","parent":"Mark Braverman","content":""},{"id":21,"href":"/tags/","title":"Tags","parent":"Mark Braverman","content":""}]